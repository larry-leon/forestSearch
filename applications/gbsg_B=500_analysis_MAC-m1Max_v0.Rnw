\documentclass[9pt]{article}
\usepackage{multicol}
\usepackage{amssymb,mathrsfs,graphicx}
\usepackage{enumerate}
\usepackage{amsthm}
\usepackage{lscape}
\usepackage{pdfpages}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{remark}
\newtheorem{remark}{Remark}

\usepackage[colorlinks=true,linkcolor={blue},citecolor={blue},urlcolor={blue}]{hyperref}
\usepackage{longtable,ctable}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{mathptmx}
\usepackage{natbib}
\usepackage{setspace}

\usepackage[utf8]{inputenc}
\usepackage{pgf}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{enumerate}
\usepackage{threeparttable}

\newcommand{\R}{R}
\newcommand{\gbsg}{gbsg}

\def\FsNg{\hbox{FS}(M_{g})}

\def\hhat{\hat\theta(\hat{H})}
\def\hchat{\hat\theta(\hat{H}^{c})}
\def\hknow{\hat\theta(H)}
\def\hcknow{\hat\theta(H^{c})}
\def\hplim{\theta^{\dagger}(H)}
\def\hcplim{\theta^{\dagger}(H^{c})}


\newcommand{\indep}{\perp \!\!\! \perp}

\textheight=9.25in \textwidth=6.0in 
\topmargin=0in
\evensidemargin=0in \oddsidemargin=0in

\begin{document}

\raggedbottom

<<echo=TRUE>>=
opts_chunk$set (warning = FALSE, message = FALSE, tidy=TRUE, echo=TRUE)
options(warn = -1)

rm(list=ls())

library(survival)
library(knitr)
library(kableExtra)

library(glmnet)

library(ggplot2)

# Following loaded in "forest_search_v0.R"
suppressMessages(library(randomForest))
#library(SPlit)

library(grf)
library(policytree)
library(DiagrammeR)

#library(cowplot)

library(data.table)
library(plyr)
library(aVirtualTwins)

suppressMessages(library(gridExtra))

# Location where code is stored
# Modified for MAC
codepath<-c("/Users/larryleon/Documents/GitHub/forestSearch/R/")
source(paste0(codepath,"source_forestsearch_v0.R"))
source_fs_functions(file_loc=codepath)

# Output grf, fs, and fs bootstrap
outgrf<-c("output/gbsg_grf.Rdata")
outfs<-c("output/gbsg_fs.Rdata")
# Boots=500
outfsboot<-c("output/gbsg_fsboot_B=500.Rdata")
# Set to null if not outputting
#outgrf<-outfs<-outfsboot<-NULL

@


<<echo=TRUE,eval=TRUE>>=
t.start.all<-proc.time()[3]
# GRF analysis
# To guide selection of binary cutpoints
df.analysis<-gbsg
df.analysis<-within(df.analysis,{
id<-as.numeric(c(1:nrow(df.analysis)))  
# time to months
time_months<-rfstime/30.4375
})

confounders.name<-c("age","meno","size","grade","nodes","pgr","er")

outcome.name<-c("time_months")
event.name<-c("status")
id.name<-c("id")
treat.name<-c("hormon")

n.min<-60
dmin.grf<-12
frac.tau<-0.60

grf.est<-grf.subg.harm.survival(data=df.analysis,confounders.name=confounders.name,outcome.name=outcome.name,
event.name=event.name,id.name=id.name,treat.name=treat.name,n.min=n.min,dmin.grf=dmin.grf,frac.tau=frac.tau,details=TRUE)

cat("Truncation point for RMST:",c(grf.est$tau.rmst),"\n")

df0.grf<-subset(grf.est$data,treat.recommend==0)
df1.grf<-subset(grf.est$data,treat.recommend==1)

# Terminal leaf corresponding to selected SG
cat("Terminal leaf:",c(grf.est$sg.harm.id),"\n")
# action=1 --> recommend control

#plot(grf.est$tree)
#plot(grf.est$tree2)
#plot(grf.est$tree3)

cat("GRF variables in selected tree","\n")
print(grf.est$tree.names)
cat("GRF cuts wrt selected tree:","\n")
print(grf.est$tree.cuts)

# Tree 2
cat("GRF variables in selected tree 2","\n")
print(grf.est$tree2.names)
cat("GRF cuts wrt selected tree 2:","\n")
print(grf.est$tree2.cuts)

# Tree 3
cat("GRF variables in selected tree 3","\n")
print(grf.est$tree3.names)
cat("GRF cuts wrt selected tree 3:","\n")
print(grf.est$tree3.cuts)

check<-subset(df.analysis, er<=0)
print(dim(check))
print(dim(df0.grf))
check<-subset(df.analysis, er>0)
print(dim(check))
print(dim(df1.grf))

# Second candidate with delta=4.6
# 2nd node for tree=3
check<-subset(df.analysis, age<=48 & pgr>8 & age>43)
print(dim(check))
# Examining Tree3, the next sg in favor of control
# Split: Age<=48, Pgr>8, Age>43
#  (43 < Age <=48) & (Pgr>8)

# Second candidate
# Not quite 6-month?

df0.grfB<-subset(df.analysis, age<=48 & pgr>8 & age>43)
df1.grfB<-subset(grf.est$data, age>48 | pgr<=8 | age<=43)

layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))
plot.subgroup(sub1=df0.grf,sub1C=df1.grf,tte.name="time_months",event.name="status",treat.name="hormon",fix.rows=FALSE,byrisk=6,show.med=FALSE)
plot.subgroup(sub1=df0.grfB,sub1C=df1.grfB,tte.name="time_months",event.name="status",treat.name="hormon",fix.rows=FALSE,byrisk=6,show.med=FALSE)

#plot.subgroup(sub1=check0,sub1C=check1,tte.name="time_months",event.name="status",treat.name="hormon",fix.rows=FALSE,byrisk=6,show.med=FALSE)
#plot.subgroup(sub1=df0.loh,sub1C=df1.loh,tte.name="time_months",event.name="status",treat.name="hormon",fix.rows=FALSE,byrisk=6,show.med=FALSE)

if(!is.null(outgrf)) save(grf.est,file=outgrf)

@

<<echo=TRUE>>=
t.done<-proc.time()[3]
t.min<-(t.done-t.start.all)/60
cat("Minutes and hours for GRF estimation",c(t.min,t.min/60),"\n")
@


\begin{figure}[h!]
\begin{center}
<<GBSGgrf_sg,echo=TRUE,out.height="400px",out.width="400px">>=
par(mfrow=c(1,2))
plot.subgroup(sub1=df0.grf,sub1C=df1.grf,tte.name="time_months",event.name="status",treat.name="hormon",fix.rows=FALSE,byrisk=9,show.med=FALSE)
@
\end{center}
\end{figure}


<<echo=TRUE,eval=TRUE>>=

# Recall, GRF splits

t.start<-proc.time()[3]

cat("GRF variables in selected tree","\n")
print(grf.est$tree.names)
cat("GRF cuts wrt selected tree:","\n")
print(grf.est$tree.cuts)

# Tree 2
cat("GRF variables in selected tree 2","\n")
print(grf.est$tree2.names)
cat("GRF cuts wrt selected tree 2:","\n")
print(grf.est$tree2.cuts)

# Tree 3
cat("GRF variables in selected tree 3","\n")
print(grf.est$tree3.names)
cat("GRF cuts wrt selected tree 3:","\n")
print(grf.est$tree3.cuts)


df.analysis<-gbsg
df.analysis<-within(df.analysis,{
id<-as.numeric(c(1:nrow(df.analysis)))  
# time to months
time_months<-rfstime/30.4375
z1a<-ifelse(er<=0,1,0)
z1b<-ifelse(er<=107,1,0)

z2a<-ifelse(pgr<=8,1,0)
z2b<-ifelse(pgr<=74,1,0)

z3a<-ifelse(age<=33,1,0)
z3b<-ifelse(age<=43,1,0)
z3c<-ifelse(age<=48,1,0)
z3d<-ifelse(age<=50,1,0) # Close to median=53

z4<-ifelse(meno==0,1,0)

z5<-ifelse(nodes<=quantile(nodes,c(0.50)),1,0)

z6<-ifelse(size<=36,1,0)

z7a<-ifelse(grade==1,1,0)
z7b<-ifelse(grade==3,1,0)

# As factors
v1a<-as.factor(z1a)
v1b<-as.factor(z1b)

v2a<-as.factor(z2a)
v2b<-as.factor(z2b)

v3a<-as.factor(z3a)
v3b<-as.factor(z3b)
v3c<-as.factor(z3c)
v3d<-as.factor(z3d)

v4<-as.factor(z4)
v5<-as.factor(z5)
v6<-as.factor(z6)

v7a<-as.factor(z7a)
v7b<-as.factor(z7b)
})


confounders.name<-c("v1a","v1b",
"v2a","v2b",
"v3a","v3b","v3c","v3d",
"v4","v5","v6","v7a","v7b")

# Note, can try smaller subset
# to check initial code run
#confounders.name<-c("v1a","v1b","v1c",
#"v2a","v2b","v2c",
#"v3a","v3b","v3c")

outcome.name<-c("time_months")
event.name<-c("status")
id.name<-c("id")
treat.name<-c("hormon")

df.confounders<-df.analysis[,confounders.name]
df.confounders<-dummy(df.confounders)

hr.threshold<-1.5   # Initital candidates 
hr.consistency<-1.25 # Candidates for many splits
pconsistency.threshold<-0.90
maxk<-4
# Limit timing for forestsearch
max.minutes<-60.0
nmin.fs<-60
#stop.threshold<-0.60 # If any sg meets this, then choose this (stop here);
m1.threshold<-Inf # Turning this off (Default)
stop.threshold<-1.0
# =1 will run through all sg's meeting HR criteria
fs.splits<-1000 # How many times to split for consistency
# vi is % factor is selected in cross-validation --> higher more important
vi.grf.min<-0.2
# Null, turns off grf screening

d.min<-10 # Min number of events for both arms (d0.min=d1.min=d.min)
# default=5

sg_focus<-"hr"


# Default FS implementation (Max consistency with harm)
# sg_focus<-"Nsg" largest SG with at least pconsistency.threshold

# The FS algorithm orders subgroups by largest hazard ratios
# and then cycles through each SG candidate (HR>1.5) 
# to calculate consistency.
# Note: there is a pstop_futile input which is default at 0.5,
# meaning that once a subgroup with consistency less than 50%
# the algorithm will stop searching: Since meeting 90%
# consistency for SG's with even lower HR's seems unlikely
# Setting pstop_futile=0 will cycle through all candidates (HR>1.5)

fs.est<-forestsearch(df=df.analysis,confounders.name=confounders.name,df.predict=df.analysis,details=TRUE,
sg_focus=sg_focus,
outcome.name=outcome.name,treat.name=treat.name,event.name=event.name,id.name=id.name,
n.min=nmin.fs,hr.threshold=hr.threshold,hr.consistency=hr.consistency,
fs.splits=fs.splits,
stop.threshold=stop.threshold,d0.min=d.min,d1.min=d.min,
pconsistency.threshold=pconsistency.threshold,
max.minutes=max.minutes,maxk=maxk,plot.sg=FALSE,vi.grf.min=vi.grf.min)

# plot.sg=TRUE will plot the estimated subgroups
# but this is plotted below

# These are the frequency each factor appears
# in a SG combination

xx<-fs.est$find.grps$out.found$hr.subgroups
covs.found<-xx[,-c(1:10)]
covs.most<-apply(covs.found,2,sum)
covs.most<-covs.most[covs.most>0]
print(covs.most)

print(fs.est$grp.consistency$result)

df0.fs<-subset(fs.est$df.pred,treat.recommend==0)
df1.fs<-subset(fs.est$df.pred,treat.recommend==1)

if(!is.null(outfs)) save(fs.est,df.analysis,confounders.name,file=outfs)

@



<<echo=TRUE>>=
t.done<-proc.time()[3]
t.min<-(t.done-t.start)/60
cat("Minutes and hours for FS estimation",c(t.min,t.min/60),"\n")
@


\begin{figure}[h!]
\begin{center}
<<GBSGgrf-fs-NSG_sg,echo=TRUE,out.height="400px",out.width="400px">>=
# Compare with GRF
layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))
plot.subgroup(sub1=df0.grf,sub1C=df1.grf,tte.name="time_months",event.name="status",treat.name="hormon",fix.rows=FALSE,byrisk=9,show.med=FALSE,subtitle1="(a)",subtitle2="(b)")
plot.subgroup(sub1=df0.fs,sub1C=df1.fs,tte.name="time_months",event.name="status",treat.name="hormon",fix.rows=FALSE,byrisk=9,show.med=FALSE,subtitle1="(c)",subtitle2="(d)")
@
\end{center}
\end{figure}


<<echo=TRUE,eval=TRUE>>=
t.start<-proc.time()[3]

library(doParallel)
registerDoParallel(parallel::detectCores(logical = FALSE))

cox.formula.boot<-as.formula(paste("Surv(time_months,status)~hormon"))
split_method<-"Random"
est.loghr<-TRUE

stop.threshold<-1.0
# Can probably set to 0.95 or 0.99,
# but we set the same as above to mimic 
# the estimation algorithm
fs.splits<-1000 
max.minutes<-6.0

NB<-10

df_temp<-fs.est$df.pred[,c("id","treat.recommend")]
dfa<-merge(df.analysis,df_temp,by="id")
df_boot_analysis<-dfa

fitH<-get_Cox_sg(df_sg=subset(df_boot_analysis,treat.recommend==0),cox.formula=cox.formula.boot,est.loghr=est.loghr)
H_obs<-fitH$est_obs # log(hr) scale
seH_obs<-fitH$se_obs
# Hc observed estimates
fitHc<-get_Cox_sg(df_sg=subset(df_boot_analysis,treat.recommend==1),cox.formula=cox.formula.boot,est.loghr=est.loghr)
Hc_obs<-fitHc$est_obs
seHc_obs<-fitHc$se_obs
rm("fitH","fitHc")

Ystar_mat<-bootYstar(
{  
ystar<-get_Ystar(boot)
},
boots=NB,
seed=8316951,
counter="boot",
export=fun_arg_list_boot
)
# Check dimension
if(dim(Ystar_mat)[1]!=NB | dim(Ystar_mat)[2]!=nrow(df_boot_analysis)) stop("Dimension of Ystar_mat does not match")

tB.start<-proc.time()[3]
# Bootstraps
resB<-bootPar(
{  
ans<-fsboot_forparallel(boot)
},
boots=NB,
seed=8316951,
counter="boot",
export=fun_arg_list_boot
)
tB.now<-proc.time()[3]
tB.min<-(tB.now-tB.start)/60

doParallel::stopImplicitCluster()

cat("Minutes for Boots",c(NB,tB.min),"\n")
cat("Projection per 100",c(tB.min*(100/NB)),"\n")
cat("Propn bootstrap subgroups found =",c(sum(!is.na(resB$H_biasadj_1))/NB),"\n")
# How many timmed out 
cat("Number timmed out=",c(sum(is.na(resB$H_biasadj_1) & resB$tmins_search>max.minutes)),"\n")

H_estimates<-get_dfRes(Hobs=H_obs,seHobs=seH_obs,H1_adj=resB$H_biasadj_1,ystar=Ystar_mat,cov_method="standard",cov_trim=0.05)

Hc_estimates<-get_dfRes(Hobs=Hc_obs,seHobs=seHc_obs,H1_adj=resB$Hc_biasadj_1,ystar=Ystar_mat,cov_method="standard",cov_trim=0.05)

print(H_estimates)
print(Hc_estimates)

if(!is.null(outfsboot)) save(fs.est,Ystar_mat,resB,H_estimates,Hc_estimates,df_boot_analysis,file=outfsboot)

@



<<echo=TRUE>>=
t.done<-proc.time()[3]
t.min<-(t.done-t.start)/60
cat("Minutes and hours for FS bootstrap",c(t.min,t.min/60),"\n")
@



<<echo=TRUE>>=

df0.fs<-subset(fs.est$df.pred,treat.recommend==0)
df1.fs<-subset(fs.est$df.pred,treat.recommend==1)

# ITT analysis
cox_itt<-summary(coxph(Surv(time_months,status)~hormon,data=fs.est$df.pred))$conf.int

  # ITT estimates
resITT<-c(round(cox_itt[c(1,3,4)],2),nrow(fs.est$df.pred))

# Forest Search
# Un-adjusted
Hstat<-c(unlist(H_estimates))[c(1,3,4)]
resH_obs<-c(c(Hstat),nrow(df0.fs))
# Bias-corrected
Hstat<-c(unlist(H_estimates))[c(5,7,8)]
resH_bc<-c(c(Hstat),nrow(df0.fs))

Hstat2<-c(unlist(H_estimates))[c(5,7,8)]
Hstat2<-round(Hstat2,2)
a<-paste0(Hstat2[1]," [")
a<-paste0(a,Hstat2[2])
a<-paste0(a,",")
a<-paste0(a,Hstat2[3])
a<-paste0(a,"]")
H_bc2<-c(a)

# Un-adjusted
Hcstat<-c(unlist(Hc_estimates))[c(1,3,4)]
resHc_obs<-c(c(Hcstat),nrow(df1.fs))
# Bias-corrected
Hcstat<-c(unlist(Hc_estimates))[c(5,7,8)]
resHc_bc<-c(c(Hcstat),nrow(df1.fs))


Hcstat2<-c(unlist(Hc_estimates))[c(5,7,8)]
Hcstat2<-round(Hcstat2,2)
a<-paste0(Hcstat2[1]," [")
a<-paste0(a,Hcstat2[2])
a<-paste0(a,",")
a<-paste0(a,Hcstat2[3])
a<-paste0(a,"]")
Hc_bc2<-c(a)

res<-rbind(resITT,resH_obs,resH_bc,resHc_obs,resHc_bc)

resf<-as.data.frame(res)

colnames(resf)<-c("HR Estimate","Lower","Upper","$\\#$ Subjects")

rnH<-c("$\\hat{H}$","$\\hat{H}_{bc}$")
rnHc<-c("$\\hat{H}^{c}$","$\\hat{H}^{c}_{bc}$")
rnItt<-c("ITT")
rownames(resf)<-c(rnItt,rnH,rnHc)
@


<<fs_tab,echo=TRUE>>=
# Resolve conflict with dplyr 
library(conflicted)
group_rows<-kableExtra::group_rows

options(knitr.kable.NA = '.',format="latex")
tab_gbsg<-kbl(resf,longtable=FALSE,align='c',format="latex",booktabs=TRUE,escape=F,digits=3,
caption="\\label{tab:gbsg} GBSG FS Analysis: Cox hazard ratio (HR) estimates for the ITT population and subgroups $H$ and $H^{c}$.
Cox model estimates are based on subgroups: The estimated subgroup $\\hat{H}$; and 
the bootstrap ($B=500$) bias-correction to $\\hat{H}$ estimates, denoted $\\hat{H}_{bc}$.  Estimates for the complement $H^{c}$ are defined analogously.
The number of subjects in each population ($\\#$ Subjects) are listed.") %>%
kable_styling(full_width = FALSE, font_size=9,latex_options="hold_position") %>%
group_rows("ITT", 1, 1) %>%
group_rows("H subgroup estimates", 2, 3) %>%
group_rows("H-complement subgroup estimates", 4, 5)
@

\Sexpr{tab_gbsg}

<<echo=TRUE>>=
t.done<-proc.time()[3]
t.min<-(t.done-t.start.all)/60
cat("Minutes and hours to finish",c(t.min,t.min/60),"\n")
cat("Machine=",c(Sys.info()[[4]]),"\n")
cat("Number of cores=",c(detectCores(logical = FALSE)),"\n")
@


\end{document}

@